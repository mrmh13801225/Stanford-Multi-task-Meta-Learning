{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from load_data import DataGenerator\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if type(model) in [nn.Linear]:\n",
    "        nn.init.xavier_uniform_(model.weight)\n",
    "        nn.init.zeros_(model.bias)\n",
    "    elif type(model) in [nn.LSTM, nn.RNN, nn.GRU]:\n",
    "        nn.init.orthogonal_(model.weight_hh_l0)\n",
    "        nn.init.xavier_uniform_(model.weight_ih_l0)\n",
    "        nn.init.zeros_(model.bias_hh_l0)\n",
    "        nn.init.zeros_(model.bias_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MANN(nn.Module):\n",
    "    def __init__(self, num_classes, samples_per_class, hidden_dim):\n",
    "        super(MANN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "\n",
    "        self.layer1 = torch.nn.LSTM(num_classes + 784, hidden_dim, batch_first=True)\n",
    "        self.layer2 = torch.nn.LSTM(hidden_dim, num_classes, batch_first=True)\n",
    "        initialize_weights(self.layer1)\n",
    "        initialize_weights(self.layer2)\n",
    "\n",
    "    def forward(self, input_images, input_labels):\n",
    "        \"\"\"\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "        \"\"\"\n",
    "        #############################\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "        #############################\n",
    "        \n",
    "        B , K_plus_1, N, _ = input_images.shape\n",
    "        K = K_plus_1 -1 \n",
    "        predictions = np.empty((K_plus_1, N, N))\n",
    "        \n",
    "        for b in range(B):\n",
    "            for k in range(K+1):\n",
    "                for n in range(N):\n",
    "                    input_label = input_labels[b][k][n]\n",
    "                    if (k == K):\n",
    "                        input_label = np.zeros(N)\n",
    "                    nn_input = torch.cat([input_images[b][k][n], input_labels], dim=-1)\n",
    "                    hidden_states1, _ = self.layer1(nn_input)\n",
    "                    prediction, _ = self.layer2(hidden_states1)\n",
    "                    predictions[b][k][n] = prediction\n",
    "                    \n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def loss_function(self, preds, labels):\n",
    "        \"\"\"\n",
    "        Computes MANN loss\n",
    "        Args:\n",
    "            preds: [B, K+1, N, N] network output\n",
    "            labels: [B, K+1, N, N] labels\n",
    "        Returns:\n",
    "            scalar loss\n",
    "        Note:\n",
    "            Loss should only be calculated on the N test images\n",
    "        \"\"\"\n",
    "        #############################\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "        pass\n",
    "        #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels, model, optim, eval=False):\n",
    "    predictions = model(images, labels)\n",
    "    loss = model.loss_function(predictions, labels)\n",
    "    if not eval:\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return predictions.detach(), loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    print(config)\n",
    "    random.seed(config.random_seed)\n",
    "    np.random.seed(config.random_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    writer = SummaryWriter(\n",
    "        f\"runs/{config.num_classes}_{config.num_shot}_{config.random_seed}_{config.hidden_dim}\"\n",
    "    )\n",
    "\n",
    "    if not os.path.isdir(\"./omniglot_resized\"):\n",
    "        gdd.download_file_from_google_drive(\n",
    "            file_id=\"1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI\",\n",
    "            dest_path=\"./omniglot_resized.zip\",\n",
    "            unzip=True,\n",
    "        )\n",
    "    assert os.path.isdir(\"./omniglot_resized\")\n",
    "\n",
    "    train_iterable = DataGenerator(\n",
    "        config.num_classes,\n",
    "        config.num_shot + 1,\n",
    "        batch_type=\"train\",\n",
    "        device=device,\n",
    "        cache=config.image_caching,\n",
    "    )\n",
    "    train_loader = iter(\n",
    "        torch.utils.data.DataLoader(\n",
    "            train_iterable,\n",
    "            batch_size=config.meta_batch_size,\n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    test_iterable = DataGenerator(\n",
    "        config.num_classes,\n",
    "        config.num_shot + 1,\n",
    "        batch_type=\"test\",\n",
    "        device=device,\n",
    "        cache=config.image_caching,\n",
    "    )\n",
    "    test_loader = iter(\n",
    "        torch.utils.data.DataLoader(\n",
    "            test_iterable,\n",
    "            batch_size=config.meta_batch_size,\n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = MANN(config.num_classes, config.num_shot + 1, config.hidden_dim)\n",
    "    model.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    times = []\n",
    "    for step in range(config.train_steps):\n",
    "        t0 = time.time()\n",
    "        i, l = next(train_loader)\n",
    "        i, l = i.to(device), l.to(device)\n",
    "        t1 = time.time()\n",
    "\n",
    "        _, ls = train_step(i, l, model, optim)\n",
    "        t2 = time.time()\n",
    "        writer.add_scalar(\"Loss/train\", ls, step)\n",
    "        times.append([t1 - t0, t2 - t1])\n",
    "\n",
    "        if (step + 1) % config.eval_freq == 0:\n",
    "            print(\"*\" * 5 + \"Iter \" + str(step + 1) + \"*\" * 5)\n",
    "            i, l = next(test_loader)\n",
    "            i, l = i.to(device), l.to(device)\n",
    "            pred, tls = train_step(i, l, model, optim, eval=True)\n",
    "            print(\"Train Loss:\", ls.cpu().numpy(), \"Test Loss:\", tls.cpu().numpy())\n",
    "            writer.add_scalar(\"Loss/test\", tls, step)\n",
    "            pred = torch.reshape(\n",
    "                pred, [-1, config.num_shot + 1, config.num_classes, config.num_classes]\n",
    "            )\n",
    "            pred = torch.argmax(pred[:, -1, :, :], axis=2)\n",
    "            l = torch.argmax(l[:, -1, :, :], axis=2)\n",
    "            acc = pred.eq(l).sum().item() / (config.meta_batch_size * config.num_classes)\n",
    "            print(\"Test Accuracy\", acc)\n",
    "            writer.add_scalar(\"Accuracy/test\", acc, step)\n",
    "\n",
    "            times = np.array(times)\n",
    "            print(f\"Sample time {times[:, 0].mean()} Train time {times[:, 1].mean()}\")\n",
    "            times = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Config object at 0x0000029C2914B4F0>\n",
      "B : 128 , K : 1 , N : 5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     image_caching \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 66\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     63\u001b[0m i, l \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mto(device), l\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     64\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 66\u001b[0m _, ls \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     68\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, ls, step)\n",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(images, labels, model, optim, eval)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28meval\u001b[39m:\n\u001b[0;32m      5\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m()\n\u001b[0;32m      7\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mdetach(), loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    num_classes = 5\n",
    "    num_shot = 1\n",
    "    num_workers = 4\n",
    "    eval_freq = 100\n",
    "    meta_batch_size = 128\n",
    "    hidden_dim = 128\n",
    "    random_seed = 123\n",
    "    learning_rate = 1e-3\n",
    "    train_steps = 25000\n",
    "    image_caching = True\n",
    "\n",
    "config = Config()\n",
    "main(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
